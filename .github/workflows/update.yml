name: Update Car Reliability Data

on:
  # Run weekly on Sunday at midnight UTC
  schedule:
    - cron: '0 0 * * 0'
  
  # Allow manual trigger with options
  workflow_dispatch:
    inputs:
      sample_percent:
        description: 'Percentage of data to fetch (1-100)'
        required: false
        default: '10'
        type: choice
        options:
          - '1'
          - '10'
          - '50'
          - '100'
      force_fetch:
        description: 'Force fresh data fetch (bypass cache)'
        required: false
        default: false
        type: boolean
  
  # Run on push to main branch
  push:
    branches:
      - main
    paths:
      - 'src/**'
      - '.github/workflows/update.yml'

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2 hour timeout for full dataset
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Set data sample percentage
        id: sample
        run: |
          # Use input if provided (manual trigger), otherwise default to 10%
          SAMPLE="${{ inputs.sample_percent || '10' }}"
          echo "DATA_SAMPLE_PERCENT=${SAMPLE}" >> $GITHUB_ENV
          echo "sample=${SAMPLE}" >> $GITHUB_OUTPUT
          echo "Sample: ${SAMPLE}%"
      
      - name: Generate cache keys
        id: cache-keys
        run: |
          # Cache key based on: sample percentage, week number, and fetch script hash
          # Each dataset gets its own cache for independent updates
          WEEK=$(date +%Y-W%V)
          SCRIPT_HASH=$(sha256sum src/download.py | cut -c1-8)
          SAMPLE="${{ steps.sample.outputs.sample }}"
          echo "inspections=inspections-${SAMPLE}pct-${WEEK}-${SCRIPT_HASH}" >> $GITHUB_OUTPUT
          echo "vehicles=vehicles-${SAMPLE}pct-${WEEK}-${SCRIPT_HASH}" >> $GITHUB_OUTPUT
          echo "fuel=fuel-${SAMPLE}pct-${WEEK}-${SCRIPT_HASH}" >> $GITHUB_OUTPUT
          echo "defects_found=defects_found-${SAMPLE}pct-${WEEK}-${SCRIPT_HASH}" >> $GITHUB_OUTPUT
          echo "defect_codes=defect_codes-${SAMPLE}pct-${WEEK}-${SCRIPT_HASH}" >> $GITHUB_OUTPUT
      
      # Cache restore for each dataset independently
      - name: Restore inspections cache
        if: inputs.force_fetch != 'true'
        id: cache-inspections
        uses: actions/cache/restore@v4
        with:
          path: data/inspections.csv
          key: ${{ steps.cache-keys.outputs.inspections }}
      
      - name: Restore vehicles cache
        if: inputs.force_fetch != 'true'
        id: cache-vehicles
        uses: actions/cache/restore@v4
        with:
          path: data/vehicles.csv
          key: ${{ steps.cache-keys.outputs.vehicles }}
      
      - name: Restore fuel cache
        if: inputs.force_fetch != 'true'
        id: cache-fuel
        uses: actions/cache/restore@v4
        with:
          path: data/fuel.csv
          key: ${{ steps.cache-keys.outputs.fuel }}
      
      - name: Restore defects_found cache
        if: inputs.force_fetch != 'true'
        id: cache-defects-found
        uses: actions/cache/restore@v4
        with:
          path: data/defects_found.csv
          key: ${{ steps.cache-keys.outputs.defects_found }}
      
      - name: Restore defect_codes cache
        if: inputs.force_fetch != 'true'
        id: cache-defect-codes
        uses: actions/cache/restore@v4
        with:
          path: data/defect_codes.csv
          key: ${{ steps.cache-keys.outputs.defect_codes }}
      
      # Fetch datasets in order: smallest first, then dependencies
      # Each dataset is saved to cache immediately after fetch (continue-on-error preserves partial progress)
      # Order: defect_codes (tiny) -> inspections (primary) -> vehicles -> fuel -> defects_found
      
      - name: Fetch defect_codes (smallest)
        if: steps.cache-defect-codes.outputs.cache-hit != 'true'
        id: fetch-defect-codes
        continue-on-error: true
        run: python src/download.py defect_codes
        env:
          RDW_APP_TOKEN: ${{ secrets.RDW_APP_TOKEN }}
      
      - name: Save defect_codes cache
        if: steps.cache-defect-codes.outputs.cache-hit != 'true' && steps.fetch-defect-codes.outcome == 'success'
        uses: actions/cache/save@v4
        with:
          path: data/defect_codes.csv
          key: ${{ steps.cache-keys.outputs.defect_codes }}
      
      - name: Fetch inspections (primary dataset)
        if: steps.cache-inspections.outputs.cache-hit != 'true'
        id: fetch-inspections
        continue-on-error: true
        run: python src/download.py inspections
        env:
          RDW_APP_TOKEN: ${{ secrets.RDW_APP_TOKEN }}
          FETCH_WORKERS: 2
      
      - name: Save inspections cache
        if: steps.cache-inspections.outputs.cache-hit != 'true' && steps.fetch-inspections.outcome == 'success'
        uses: actions/cache/save@v4
        with:
          path: data/inspections.csv
          key: ${{ steps.cache-keys.outputs.inspections }}
      
      - name: Fetch vehicles
        if: steps.cache-vehicles.outputs.cache-hit != 'true' && (steps.cache-inspections.outputs.cache-hit == 'true' || steps.fetch-inspections.outcome == 'success')
        id: fetch-vehicles
        continue-on-error: true
        run: python src/download.py vehicles --kentekens-from data/inspections.csv
        env:
          RDW_APP_TOKEN: ${{ secrets.RDW_APP_TOKEN }}
          FETCH_WORKERS: 2
      
      - name: Save vehicles cache
        if: steps.fetch-vehicles.outcome == 'success'
        uses: actions/cache/save@v4
        with:
          path: data/vehicles.csv
          key: ${{ steps.cache-keys.outputs.vehicles }}
      
      - name: Fetch fuel
        if: steps.cache-fuel.outputs.cache-hit != 'true' && (steps.cache-inspections.outputs.cache-hit == 'true' || steps.fetch-inspections.outcome == 'success')
        id: fetch-fuel
        continue-on-error: true
        run: python src/download.py fuel --kentekens-from data/inspections.csv
        env:
          RDW_APP_TOKEN: ${{ secrets.RDW_APP_TOKEN }}
          FETCH_WORKERS: 2
      
      - name: Save fuel cache
        if: steps.fetch-fuel.outcome == 'success'
        uses: actions/cache/save@v4
        with:
          path: data/fuel.csv
          key: ${{ steps.cache-keys.outputs.fuel }}
      
      - name: Fetch defects_found
        if: steps.cache-defects-found.outputs.cache-hit != 'true' && (steps.cache-inspections.outputs.cache-hit == 'true' || steps.fetch-inspections.outcome == 'success')
        id: fetch-defects-found
        continue-on-error: true
        run: python src/download.py defects_found --kentekens-from data/inspections.csv
        env:
          RDW_APP_TOKEN: ${{ secrets.RDW_APP_TOKEN }}
          FETCH_WORKERS: 2
      
      - name: Save defects_found cache
        if: steps.fetch-defects-found.outcome == 'success'
        uses: actions/cache/save@v4
        with:
          path: data/defects_found.csv
          key: ${{ steps.cache-keys.outputs.defects_found }}
      
      # Check if all required datasets are available (either cached or fetched)
      - name: Verify all datasets available
        id: verify-data
        run: |
          missing=""
          for f in inspections vehicles fuel defects_found defect_codes; do
            if [ ! -f "data/${f}.csv" ]; then
              missing="${missing} ${f}"
            fi
          done
          if [ -n "$missing" ]; then
            echo "Missing datasets:$missing"
            exit 1
          fi
          echo "All datasets available"
      
      - name: Create fetch metadata
        run: |
          cat > data/fetch_metadata.json << EOF
          {
            "sample_percent": ${{ steps.sample.outputs.sample }},
            "fetched_at": "$(date -Iseconds)",
            "cache_status": {
              "inspections": "${{ steps.cache-inspections.outputs.cache-hit == 'true' && 'cached' || 'fetched' }}",
              "vehicles": "${{ steps.cache-vehicles.outputs.cache-hit == 'true' && 'cached' || 'fetched' }}",
              "fuel": "${{ steps.cache-fuel.outputs.cache-hit == 'true' && 'cached' || 'fetched' }}",
              "defects_found": "${{ steps.cache-defects-found.outputs.cache-hit == 'true' && 'cached' || 'fetched' }}",
              "defect_codes": "${{ steps.cache-defect-codes.outputs.cache-hit == 'true' && 'cached' || 'fetched' }}"
            }
          }
          EOF
      
      - name: Report cache status
        run: |
          echo "### Data Fetch Summary (${{ steps.sample.outputs.sample }}% sample)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Dataset | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| inspections | ${{ steps.cache-inspections.outputs.cache-hit == 'true' && 'cached' || 'fetched' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| vehicles | ${{ steps.cache-vehicles.outputs.cache-hit == 'true' && 'cached' || 'fetched' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| fuel | ${{ steps.cache-fuel.outputs.cache-hit == 'true' && 'cached' || 'fetched' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| defects_found | ${{ steps.cache-defects-found.outputs.cache-hit == 'true' && 'cached' || 'fetched' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| defect_codes | ${{ steps.cache-defect-codes.outputs.cache-hit == 'true' && 'cached' || 'fetched' }} |" >> $GITHUB_STEP_SUMMARY
      
      - name: Process data
        run: python src/process_data.py
      
      - name: Generate static site
        run: python src/generate_site.py
      
      - name: Setup Pages
        uses: actions/configure-pages@v4
      
      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: 'site'
      
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
      
      - name: Build summary
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Build Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Sample:** ${{ steps.sample.outputs.sample }}%" >> $GITHUB_STEP_SUMMARY
          echo "**Deployed to:** ${{ steps.deployment.outputs.page_url }}" >> $GITHUB_STEP_SUMMARY
