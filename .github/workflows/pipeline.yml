name: Data Pipeline

on:
  schedule:
    - cron: '0 0 * * 0'  # Sunday midnight UTC
  workflow_dispatch:
    inputs:
      force_refresh:
        description: 'Force data refresh (ignore cache)'
        required: false
        default: false
        type: boolean
  push:
    branches:
      - main

concurrency:
  group: pipeline-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  pages: write
  id-token: write
  actions: read

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '22'

jobs:
  download:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: gekentekende_voertuigen
            use_days_limit: false
            timeout: 60
            min_size: 1000
          - name: meldingen_keuringsinstantie
            use_days_limit: true
            timeout: 60
            min_size: 1000
          - name: geconstateerde_gebreken
            use_days_limit: true
            timeout: 60
            min_size: 1000
          - name: gebreken
            use_days_limit: false
            timeout: 15
            min_size: 100
          - name: brandstof
            use_days_limit: false
            timeout: 60
            min_size: 1000
    timeout-minutes: ${{ matrix.timeout }}

    steps:
      - uses: actions/checkout@v4

      - name: Calculate cache key
        id: cache-key
        run: |
          WEEK=$(date +'%Y-W%V')
          if [ "${{ matrix.use_days_limit }}" = "true" ] && [ -n "$INSPECTION_DAYS_LIMIT" ]; then
            KEY="${{ matrix.name }}-$WEEK-days-$INSPECTION_DAYS_LIMIT"
          else
            KEY="${{ matrix.name }}-$WEEK"
          fi
          echo "key=$KEY" >> $GITHUB_OUTPUT
        env:
          INSPECTION_DAYS_LIMIT: ${{ vars.INSPECTION_DAYS_LIMIT }}

      - name: Cache dataset
        id: cache
        if: github.event.inputs.force_refresh != 'true' && github.event_name != 'schedule'
        uses: actions/cache@v4
        with:
          path: data/raw/${{ matrix.name }}.json
          key: ${{ steps.cache-key.outputs.key }}

      - name: Install uv
        if: steps.cache.outputs.cache-hit != 'true'
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"
          enable-cache: true
          cache-dependency-glob: "scripts/uv.lock"

      - name: Set up Python
        if: steps.cache.outputs.cache-hit != 'true'
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        if: steps.cache.outputs.cache-hit != 'true'
        run: cd scripts && uv sync --frozen

      - name: Download dataset
        if: steps.cache.outputs.cache-hit != 'true'
        run: cd scripts && uv run python data_download.py --dataset ${{ matrix.name }}
        env:
          RDW_APP_TOKEN: ${{ secrets.RDW_APP_TOKEN }}
          INSPECTION_DAYS_LIMIT: ${{ vars.INSPECTION_DAYS_LIMIT }}

      - name: Verify download
        run: |
          FILE="data/raw/${{ matrix.name }}.json"
          if [ ! -f "$FILE" ]; then
            echo "ERROR: Download failed - $FILE not found"
            exit 1
          fi
          SIZE=$(stat -c%s "$FILE")
          echo "File size: $((SIZE / 1024)) KB"
          if [ "$SIZE" -lt ${{ matrix.min_size }} ]; then
            echo "ERROR: File too small (< ${{ matrix.min_size }} bytes)"
            exit 1
          fi

      - uses: actions/upload-artifact@v4
        with:
          name: raw-${{ matrix.name }}
          path: data/raw/${{ matrix.name }}.json
          retention-days: 1

  merge:
    runs-on: ubuntu-latest
    needs: [download]
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: raw-*
          path: data/raw
          merge-multiple: true

      - name: Verify all files
        run: |
          echo "Downloaded files:"
          ls -lh data/raw/
          for f in gekentekende_voertuigen meldingen_keuringsinstantie geconstateerde_gebreken gebreken brandstof; do
            if [ ! -f "data/raw/${f}.json" ]; then
              echo "ERROR: Missing ${f}.json"
              exit 1
            fi
          done
          echo "All datasets present"

      - uses: actions/upload-artifact@v4
        with:
          name: raw-data
          path: data/raw
          retention-days: 1

  process:
    runs-on: ubuntu-latest
    needs: [merge]
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - name: Download raw data
        uses: actions/download-artifact@v4
        with:
          name: raw-data
          path: data/raw

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"
          enable-cache: true
          cache-dependency-glob: "scripts/uv.lock"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: cd scripts && uv sync --frozen

      - name: Verify raw data
        run: |
          echo "Checking raw data files:"
          ls -lh data/raw/
          for f in gekentekende_voertuigen meldingen_keuringsinstantie geconstateerde_gebreken gebreken brandstof; do
            if [ ! -f "data/raw/${f}.json" ]; then
              echo "ERROR: Missing ${f}.json"
              exit 1
            fi
          done
          echo "All datasets present"

      - name: Process data
        run: cd scripts && uv run python data_process.py

      - uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: data/processed
          retention-days: 1

  build:
    runs-on: ubuntu-latest
    needs: [process]
    timeout-minutes: 15

    steps:
      - uses: actions/checkout@v4

      - name: Download processed data
        uses: actions/download-artifact@v4
        with:
          name: processed-data
          path: data/processed

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: web/package-lock.json

      - name: Copy data to web public directory
        run: |
          mkdir -p web/public/data
          cp -r data/processed/* web/public/data/

      - name: Install dependencies
        working-directory: web
        run: npm ci

      - name: Build site
        working-directory: web
        run: npm run build

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: web/out

  deploy:
    runs-on: ubuntu-latest
    needs: [build]
    timeout-minutes: 10
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
