name: Download Data

on:
  # Run weekly on Sunday at midnight UTC
  schedule:
    - cron: '0 0 * * 0'
  
  # Allow manual trigger with options
  workflow_dispatch:
    inputs:
      sample_percent:
        description: 'Percentage of data to fetch (1-100)'
        required: false
        default: '100'
        type: choice
        options:
          - '1'
          - '10'
          - '50'
          - '100'
      force_fetch:
        description: 'Force fresh data fetch (bypass cache)'
        required: false
        default: false
        type: boolean
  
  # Run on push to main branch
  push:
    branches:
      - main
    paths:
      - 'src/download.py'
      - '.github/workflows/download.yml'

permissions:
  contents: read

# Allow only one concurrent download
concurrency:
  group: "download"
  cancel-in-progress: false

jobs:
  # Download inspections in parallel partitions (36 jobs: 0-9, A-Z)
  download-inspections:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      max-parallel: 10
      matrix:
        partition: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
                    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J',
                    'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',
                    'U', 'V', 'W', 'X', 'Y', 'Z']
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Set data sample percentage
        id: sample
        run: |
          if [ -n "${{ inputs.sample_percent }}" ]; then
            SAMPLE="${{ inputs.sample_percent }}"
          elif [ "${{ github.event_name }}" = "schedule" ]; then
            SAMPLE="100"
          else
            SAMPLE="10"
          fi
          echo "DATA_SAMPLE_PERCENT=${SAMPLE}" >> $GITHUB_ENV
          echo "sample=${SAMPLE}" >> $GITHUB_OUTPUT
      
      - name: Generate cache key
        id: cache-key
        run: |
          WEEK=$(date +%Y-W%V)
          SCRIPT_HASH=$(sha256sum src/download.py | cut -c1-8)
          SAMPLE="${{ steps.sample.outputs.sample }}"
          echo "key=inspections-${{ matrix.partition }}-${SAMPLE}pct-${WEEK}-${SCRIPT_HASH}" >> $GITHUB_OUTPUT
      
      - name: Restore partition cache
        if: inputs.force_fetch != 'true'
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            data/inspections_${{ matrix.partition }}.csv
            data/inspections_${{ matrix.partition }}.complete
          key: ${{ steps.cache-key.outputs.key }}
      
      - name: Check if partition complete
        id: check-complete
        run: |
          if [ -f "data/inspections_${{ matrix.partition }}.complete" ]; then
            echo "complete=true" >> $GITHUB_OUTPUT
          else
            echo "complete=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Fetch inspections partition ${{ matrix.partition }}
        if: steps.check-complete.outputs.complete != 'true'
        id: fetch
        run: |
          python src/download.py inspections --partition ${{ matrix.partition }}
          touch data/inspections_${{ matrix.partition }}.complete
        env:
          RDW_APP_TOKEN: ${{ secrets.RDW_APP_TOKEN }}
      
      - name: Save partition cache
        if: steps.fetch.outcome == 'success' || steps.check-complete.outputs.complete == 'true'
        uses: actions/cache/save@v4
        with:
          path: |
            data/inspections_${{ matrix.partition }}.csv
            data/inspections_${{ matrix.partition }}.complete
          key: ${{ steps.cache-key.outputs.key }}
      
      - name: Upload partition artifact
        uses: actions/upload-artifact@v4
        with:
          name: inspections-${{ matrix.partition }}
          path: data/inspections_${{ matrix.partition }}.csv
          retention-days: 1

  # Download other datasets (smaller, don't need partitioning)
  download-other:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Set data sample percentage
        id: sample
        run: |
          if [ -n "${{ inputs.sample_percent }}" ]; then
            SAMPLE="${{ inputs.sample_percent }}"
          elif [ "${{ github.event_name }}" = "schedule" ]; then
            SAMPLE="100"
          else
            SAMPLE="10"
          fi
          echo "DATA_SAMPLE_PERCENT=${SAMPLE}" >> $GITHUB_ENV
          echo "sample=${SAMPLE}" >> $GITHUB_OUTPUT
      
      - name: Generate cache keys
        id: cache-keys
        run: |
          WEEK=$(date +%Y-W%V)
          SCRIPT_HASH=$(sha256sum src/download.py | cut -c1-8)
          SAMPLE="${{ steps.sample.outputs.sample }}"
          echo "defect_codes=defect_codes-${SAMPLE}pct-${WEEK}-${SCRIPT_HASH}" >> $GITHUB_OUTPUT
      
      - name: Restore defect_codes cache
        if: inputs.force_fetch != 'true'
        id: cache-defect-codes
        uses: actions/cache/restore@v4
        with:
          path: |
            data/defect_codes.csv
            data/defect_codes.complete
          key: ${{ steps.cache-keys.outputs.defect_codes }}
      
      - name: Check defect_codes complete
        id: check-defect-codes
        run: |
          if [ -f "data/defect_codes.complete" ]; then
            echo "complete=true" >> $GITHUB_OUTPUT
          else
            echo "complete=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Fetch defect_codes
        if: steps.check-defect-codes.outputs.complete != 'true'
        id: fetch-defect-codes
        run: |
          python src/download.py defect_codes
          touch data/defect_codes.complete
        env:
          RDW_APP_TOKEN: ${{ secrets.RDW_APP_TOKEN }}
      
      - name: Save defect_codes cache
        if: steps.fetch-defect-codes.outcome == 'success' || steps.check-defect-codes.outputs.complete == 'true'
        uses: actions/cache/save@v4
        with:
          path: |
            data/defect_codes.csv
            data/defect_codes.complete
          key: ${{ steps.cache-keys.outputs.defect_codes }}
      
      - name: Upload defect_codes artifact
        uses: actions/upload-artifact@v4
        with:
          name: defect_codes
          path: data/defect_codes.csv
          retention-days: 1

  # Merge inspections partitions and download dependent datasets
  merge-and-download-dependent:
    needs: [download-inspections, download-other]
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Set data sample percentage
        id: sample
        run: |
          if [ -n "${{ inputs.sample_percent }}" ]; then
            SAMPLE="${{ inputs.sample_percent }}"
          elif [ "${{ github.event_name }}" = "schedule" ]; then
            SAMPLE="100"
          else
            SAMPLE="10"
          fi
          echo "DATA_SAMPLE_PERCENT=${SAMPLE}" >> $GITHUB_ENV
          echo "sample=${SAMPLE}" >> $GITHUB_OUTPUT
      
      - name: Generate cache keys
        id: cache-keys
        run: |
          WEEK=$(date +%Y-W%V)
          SCRIPT_HASH=$(sha256sum src/download.py | cut -c1-8)
          SAMPLE="${{ steps.sample.outputs.sample }}"
          echo "vehicles=vehicles-${SAMPLE}pct-${WEEK}-${SCRIPT_HASH}" >> $GITHUB_OUTPUT
          echo "fuel=fuel-${SAMPLE}pct-${WEEK}-${SCRIPT_HASH}" >> $GITHUB_OUTPUT
          echo "defects_found=defects_found-${SAMPLE}pct-${WEEK}-${SCRIPT_HASH}" >> $GITHUB_OUTPUT
      
      - name: Download all inspections partitions
        uses: actions/download-artifact@v4
        with:
          pattern: inspections-*
          path: data/partitions
          merge-multiple: false
      
      - name: Merge inspections partitions
        run: |
          mkdir -p data
          # Get header from first partition file
          first_file=$(find data/partitions -name "*.csv" | head -1)
          head -1 "$first_file" > data/inspections.csv
          # Append data from all partitions (skip headers)
          for f in data/partitions/*/inspections_*.csv; do
            tail -n +2 "$f" >> data/inspections.csv
          done
          rm -rf data/partitions
          echo "Merged inspections: $(wc -l < data/inspections.csv) lines"
      
      - name: Download defect_codes artifact
        uses: actions/download-artifact@v4
        with:
          name: defect_codes
          path: data
      
      # Restore caches for dependent datasets
      - name: Restore vehicles cache
        if: inputs.force_fetch != 'true'
        id: cache-vehicles
        uses: actions/cache/restore@v4
        with:
          path: |
            data/vehicles.csv
            data/vehicles.complete
          key: ${{ steps.cache-keys.outputs.vehicles }}
      
      - name: Restore fuel cache
        if: inputs.force_fetch != 'true'
        id: cache-fuel
        uses: actions/cache/restore@v4
        with:
          path: |
            data/fuel.csv
            data/fuel.complete
          key: ${{ steps.cache-keys.outputs.fuel }}
      
      - name: Restore defects_found cache
        if: inputs.force_fetch != 'true'
        id: cache-defects-found
        uses: actions/cache/restore@v4
        with:
          path: |
            data/defects_found.csv
            data/defects_found.complete
          key: ${{ steps.cache-keys.outputs.defects_found }}
      
      - name: Check completion status
        id: check-complete
        run: |
          for ds in vehicles fuel defects_found; do
            if [ -f "data/${ds}.complete" ]; then
              echo "${ds}=true" >> $GITHUB_OUTPUT
            else
              echo "${ds}=false" >> $GITHUB_OUTPUT
            fi
          done
      
      - name: Fetch vehicles
        if: steps.check-complete.outputs.vehicles != 'true'
        id: fetch-vehicles
        continue-on-error: true
        run: |
          python src/download.py vehicles --kentekens-from data/inspections.csv
          touch data/vehicles.complete
        env:
          RDW_APP_TOKEN: ${{ secrets.RDW_APP_TOKEN }}
          FETCH_WORKERS: 2
      
      - name: Save vehicles cache
        if: steps.fetch-vehicles.outcome == 'success'
        uses: actions/cache/save@v4
        with:
          path: |
            data/vehicles.csv
            data/vehicles.complete
          key: ${{ steps.cache-keys.outputs.vehicles }}
      
      - name: Fetch fuel
        if: steps.check-complete.outputs.fuel != 'true'
        id: fetch-fuel
        continue-on-error: true
        run: |
          python src/download.py fuel --kentekens-from data/inspections.csv
          touch data/fuel.complete
        env:
          RDW_APP_TOKEN: ${{ secrets.RDW_APP_TOKEN }}
          FETCH_WORKERS: 2
      
      - name: Save fuel cache
        if: steps.fetch-fuel.outcome == 'success'
        uses: actions/cache/save@v4
        with:
          path: |
            data/fuel.csv
            data/fuel.complete
          key: ${{ steps.cache-keys.outputs.fuel }}
      
      - name: Fetch defects_found
        if: steps.check-complete.outputs.defects_found != 'true'
        id: fetch-defects-found
        continue-on-error: true
        run: |
          python src/download.py defects_found --kentekens-from data/inspections.csv
          touch data/defects_found.complete
        env:
          RDW_APP_TOKEN: ${{ secrets.RDW_APP_TOKEN }}
          FETCH_WORKERS: 2
      
      - name: Save defects_found cache
        if: steps.fetch-defects-found.outcome == 'success'
        uses: actions/cache/save@v4
        with:
          path: |
            data/defects_found.csv
            data/defects_found.complete
          key: ${{ steps.cache-keys.outputs.defects_found }}
      
      - name: Verify all datasets available
        run: |
          for f in inspections vehicles fuel defects_found defect_codes; do
            if [ ! -f "data/${f}.csv" ]; then
              echo "ERROR: Missing data/${f}.csv"
              exit 1
            fi
            echo "OK: data/${f}.csv ($(wc -l < data/${f}.csv) lines)"
          done
      
      - name: Create fetch metadata
        run: |
          cat > data/fetch_metadata.json << EOF
          {
            "sample_percent": ${{ steps.sample.outputs.sample }},
            "fetched_at": "$(date -Iseconds)",
            "workflow": "download.yml",
            "run_id": "${{ github.run_id }}"
          }
          EOF
      
      - name: Upload combined data artifact
        uses: actions/upload-artifact@v4
        with:
          name: all-data
          path: |
            data/inspections.csv
            data/vehicles.csv
            data/fuel.csv
            data/defects_found.csv
            data/defect_codes.csv
            data/fetch_metadata.json
          retention-days: 1
      
      - name: Download summary
        run: |
          echo "### Download Summary (${{ steps.sample.outputs.sample }}% sample)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Dataset | Lines |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|-------|" >> $GITHUB_STEP_SUMMARY
          for f in inspections vehicles fuel defects_found defect_codes; do
            lines=$(wc -l < "data/${f}.csv")
            echo "| ${f} | ${lines} |" >> $GITHUB_STEP_SUMMARY
          done
